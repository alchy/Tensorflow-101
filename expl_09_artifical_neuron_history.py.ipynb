{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stručná historie neuronek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I přes to, že existuje hondě analogií mezi základním konceptem neuropsychologie a modely umělých neuronových sítí, jsou oba tyto světy nesmírně odlišné. Budeme mluvit o neuronových sítích tak, že jsou částečně inspirovány tím, jak současná neuropsychologie popisuje nervové systémy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*neuron: a specialized cell transmitting nerve impulses; a nerve cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1940: začátek neuronových sítí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>McCulloch&Pitts</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warren McCulloch a Walter Pitts navrhli první umělou neuronovou síť. V roce <b>1943</b> o tom publikovali v bulletinu mathematiké biofiziky. Váhy neuronů jsou nastaveny tak, že neurony plní specifické zadání jednoduché logické funkce. Neurony mohou být spojeny do sítě tak, aby tato síť reprezentovala kombinační nebo logickou funkci. Signál cestující skrze síť z jednoho neuronu do druhého je přenesen vždy v jednom kroku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model neuronu z roku 1943 má step-aktivační funkci a proto výzkum prezentoval funkci tohoto neuronu při simulaci logických funkcí. Idea prahu, při kterém je neuron aktivován (aktivační funkce) je použita i v dnešních modelech neuronových sítí, ale aktivační funkce nemívá binární charakter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1950 a 1960: první zlatá éra neuronových sítí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>John von Neumann</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I přes to, že se na neuronové sítě často nahlíželo jako na alternativu (nebo doplněk) tradičních výpočetních metod, toto téma zaujalo i von Neumanna, otce moderního computingu. Také von Neumann se velmi zajímal o možnost modelovat funkci mozku [von Neumann, 1958]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perceptrons</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oproti McCulloch–Pitts neuronu je perceptron více flexibilní. McCulloch–Pitts model využíval předdefinované váhy vstupů a pro změnu funkce úpravu aktivačního prahu nebo zapojení, Perceptron využívá proměnné váhy vstupů a tyto při procesu učení přizpůsobuje tak, aby dosáhl požadovaného výstupu. Stejně jako McCulloch–Pitts neuron, Perceptron používá treshold aktivační funkci. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Počáteční úspěch perceptronů vedel k poměrně optimistickým proklamacím. Reputace perceptronu byla ale do značné míry pokažena ukázkou jeho omezení [Minsky & Papert, 1969]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1970: pokračování výzkumu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I přes to, že Minsky and Papert poukázali na značná omezení perceptronu, výzkum v oblasti umělých neuronových síti pokračoval. Mnoho v současnosti známých jmen v oboru strojového učení a umělé inteligence během 70tých let publikovalo svoje práce - Teuvo Kohonen, James Anderson, Stephen Grossberg, Gail Carpenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1980: enthusiasmus se vrací"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Backpropagation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dva důvody proč v sedmdesátých letech selhal koncept perceptronů bylo to, že zapojení single-layer perceptron nebylo schopné řešit složitější problémy, jako například logickou funkci XOR. Pro vícevrstvé zapojení perceptronu zase chyběla obecná metoda učení takové sítě.  \n",
    "Metoda umožňující učit vícevrstvé sítě byla sice také objevena v sedmdesátých letech, ale nedosáhla dostatečné publicity. Teprve v osmdesátých letech se jí podařilo dostatečně prosadit a to umožnilo další rozvoj na poli neuronových sítí. Dalším důvodem bylo, že v osmdesátých letech začaly být dostupné počítače s větším výkonem a na straně hardware začala postupně ubývat omezení plynoucí z kapacity a rychlosti. I přes to, že ani současný hardware není pro větší modely neuronových sítí dostatečně výkonný, výkonové omezení dnes díky možnostem paraelního computingu přispívá k odstranění posledních překážek využití neuronových sítí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zpět k Tensrorflow, neuron popsaný tf Grafem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pictures/artificial_neuron.png \"https://inspirehep.net/record/1300728/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron bude mít tři vstupy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr_inputs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    neuron_inputs = tf.placeholder(tf.float32, [nr_inputs, 1], name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('neuron'):\n",
    "\n",
    "    with tf.name_scope('Weights'):\n",
    "        neuron_weights = tf.placeholder(tf.float32, [nr_inputs, 1], name='Weight')\n",
    "\n",
    "    with tf.name_scope('bias'):\n",
    "        neuron_bias = tf.placeholder(tf.float32, [1], name='bias')\n",
    "\n",
    "    with tf.name_scope('neuron_fn'):\n",
    "        neuron_fn1_out = tf.multiply(neuron_inputs, neuron_weights, name='Wx')\n",
    "        neuron_fn2 = tf.reduce_sum(neuron_fn1_out)\n",
    "        neuron_fn3 = tf.add(neuron_fn2, neuron_bias)\n",
    "        neuron_out = tf.sigmoid(neuron_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90720707]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./tensorboard_example\", sess.graph)\n",
    "    neuron_inputs_feed =  [[0.8], [0.8], [0.8]]\n",
    "    neuron_weights_feed = [[0.1], [0.5], [1.0]]\n",
    "    neuron_bias_feed = [1.0]\n",
    "                            \n",
    "    res_neuron_out = sess.run(neuron_out,\n",
    "        feed_dict={neuron_inputs: neuron_inputs_feed,\n",
    "                   neuron_weights: neuron_weights_feed,\n",
    "                   neuron_bias: neuron_bias_feed})\n",
    "\n",
    "    print(res_neuron_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard.exe --logdir=\".\\tensorboard_example\" --port 9000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
