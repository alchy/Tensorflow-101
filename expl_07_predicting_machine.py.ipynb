{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroj na předpověď"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principy, které si nyní ukážeme jsou aplikované při konstrukci všech supervised machile learning modelů. Náš velmi zjednodušený supervised machine learning model bude mít jeden vstup a jeden výstup. Jeho úkolem je najít hodnotu W, která odpovídá konstantě 62.13712, která se používá při převodu kilometrů na míle. Funkce konverze je lineární y = x * W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zažité je označovat vstup modelu jako X, požadovaný výstup modelu Y a předpověď modelu ŷ [y-hat]. Pro určení správné hodnoty W využijeme funkce Tensorflow a to funkce optimalizační. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dá se říci, že čím je funkce, na kterou chceme model trénovat, komplexnější, tím více vzorků dané funkce potřebujeme použít při tréningu. S rostoucí komplexitou funkce roste i komplexita modelu - např. více neuronů, více vrstev, kombinace různých aktivačních funkcí, atd... V naší ukázce převodu kilometrů na míle nám by nám stačilo minimální množství vzorků, resp. pro správné určení hodnoty W by nám ¨stačil jediný vzorek, kde X != 0. Abychom se v ukázce více přiblížili reálnému procesu učení, vzorků použijeme více."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pictures/machine_learning_small.jpg  \"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto jsou naše vzorky funkce v X a Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "nr_inputs = 1\n",
    "\n",
    "X =   [ [8.],       [45.],      [323.],     [0.0], [100] ]\n",
    "Y =   [ [4.970970], [27.96170], [200.7029], [0.0], [62.13712] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Vzorky funkce, které máme k dispozici, rozdělíme.</b> Část z nich použijeme na učení našeho modelu, druhou si necháme k tomu, abychom si ověřili, zda model je schopen provádět předpověď i nad daty, která nebyla použita při tréningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:  [[8.0], [45.0], [323.0]]\n",
      "train_y:  [[4.97097], [27.9617], [200.7029]]\n",
      "test_x:  [[0.0], [100]]\n",
      "test_y:  [[0.0], [62.13712]]\n"
     ]
    }
   ],
   "source": [
    "train_x =   X[:3]\n",
    "train_y =   Y[:3]\n",
    "print('train_x: ', train_x)\n",
    "print('train_y: ', train_y)\n",
    "\n",
    "test_x  =   X[3:]\n",
    "test_y  =   Y[3:]\n",
    "print('test_x: ', test_x)\n",
    "print('test_y: ', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní připravíme Tensory, které budeme pro výpočet v grafu potřebovat. Ve scope 'input' definujeme placeholder pro vložení vstupních dat to grafu, ve scope 'target' pak placeholder, kde předáváme modelu 'label', tedy správný výsledek k příslušnému vstupu. Definice scope není povinná, má zde jen pomoci lepší přehlednosti grafu zobrazeného na Tensorboardu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "   x = tf.placeholder(tf.float32, [None, nr_inputs], name='input')\n",
    "\n",
    "with tf.name_scope('target'):\n",
    "   y = tf.placeholder(tf.float32, [None, 1], name='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zde je vnitřek našeho 'prediction machine' modelu. Za sofistikovaným algoritmem strojového učení se v našem zjednodušeném příkladu skrývá pouze lineární funkce x * W, ale jak uvidíte později, každý neuron použitý v neuronových sítích, má v sobě rovněž obyčejnou lineární funkci. Tato funkce mu umožňuje provádět klasifikaci. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Variable je pro Tensorflow tzv. Trainable Tensor. Trainable Tensory mohou, a jsou, měněny funkcemi Tensorflow - optimalizačnímy algoritmy. Optimalizační algoritmus má za úkol provést takové změny hodnot Tensoru/Tensorů typu Variable, aby funkce, ve které jsou Tensory typu Variable použity, konvergovala k co nejrychleji k co nejmenší hodnotě chyby. Algoritmus učení našeho modelu je zachycen na následujícím obrázku:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pictures/ML_pattern.png \"Suervised ML Pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V prvním kroku, na obrázku zelenou barvou, <font color='green'>do Grafu vložíme pomocí Tensoru typu placeholder naše vzorky dat X a Y</font>. Nad těmito daty spustíme výpočet, což znamená, že <font color='blue'>voláme funkci train</font> - je definována v modrém obdélníčku. Funkce <font color='red'>train</font> spouští 'cost_function', na obrázku červená, která jako parametr používá funckci prediction, žlutě. Na tomto případě je vidět vzájemná provázanost jednotlivých částí grafu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('p_machine'):\n",
    "\n",
    "    with tf.name_scope('Wtrainable'):\n",
    "        # Weight - Variable is by default trainable\n",
    "        W = tf.Variable(tf.random_uniform([nr_inputs, 1], -1, 1), name=\"rand_W\")\n",
    "        tf.trainable_variables()\n",
    "    \n",
    "    with tf.name_scope('prediction_fn'):\n",
    "        pred = tf.matmul(x, W, name='Wx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak se Tensorflow přilíží ke správnému výsledku? Tensorflow provede úpravu hodnoty tensoru W a srovnáním se správným výsledkem (pred - y) spočítá, zda se hodnota chyby zvětšila, nebo zmenšila. Potom se vydá v optimalizaci hodnoty tensoru W takovým směrem, aby hodnota chyby po další iteraci klesla. Algoritmus provádějící optimalizaci parametrů modelu se nazývá <b>Gradient Descent</b>. Parametr 'learning_rate' zásadně ovlivňuje proces učení, optimalizačnímu algoritmu říká, v jak velkých krocích má postupovat při úpravě našeho Variable Tensoru. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"training\") as scope:\n",
    "    \n",
    "    with tf.name_scope(\"cost_fn\") as scope:\n",
    "        cost_function = tf.reduce_sum(pred - y) ** 2\n",
    "        \n",
    "    #train = tf.train.AdamOptimizer().minimize(cost_function)\n",
    "    #vyzkoušej  \n",
    "    #train = tf.train.GradientDescentOptimizer(0.01).minimize(cost_function)\n",
    "    #výpočet by měl selhat, hodnota NaN, příliš velký slope \n",
    "    train = tf.train.GradientDescentOptimizer(0.000001).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud je parametr 'learning_rate' příliš velký, optimalizační algoritmus nemusí konvergovat ke správnému výsledku - velká hodnota parametru 'learning_rate' by 'přeskočila' tzv. globální minimum, kde je hodnota chyby (cost) predikce našeho modelu nejmenší. Ukázka chování optimalizačního algoritmu v případě, kdy je parametr 'learning_rate' příliš velký, je vidět na obrázku B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pictures/gradient_descent_slope.png \"Gradient Descent slope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možná trochu matoucí názvy <b>'cost'</b>, případně <b>'loss'</b> jsou v ML zažité termíny pro <b>chybu</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tady už vše necháme na Tensorflow. V momentě, kdy bude náš model generovat dostatečně malou chybu, proces učení ukončíme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  cost:  4084.49\n",
      "Weight(s): \n",
      "[[ 0.6212129]]\n",
      "Predidctions for: \n",
      "[[0.0], [100]]\n",
      "is: \n",
      "[[  0.       ]\n",
      " [ 62.1212883]]\n",
      "100Km/h = 62.13712mph\n"
     ]
    }
   ],
   "source": [
    "# loop through the Graph until the error is low enough\n",
    "with tf.Session() as sess:\n",
    "    tb_writer = tf.summary.FileWriter(\"./tensorboard_example\", sess.graph)\n",
    "    tb_scalar_cost = tf.summary.scalar(\"cost\", cost_function)\n",
    " \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_function_result = 1000.0\n",
    "    training_epoch = -1\n",
    "    \n",
    "    while cost_function_result > 0.01:\n",
    "        \n",
    "        training_epoch += 1\n",
    "        \n",
    "        _, tb_scalar_cost_report, cost_function_result = \\\n",
    "            sess.run([train, tb_scalar_cost, cost_function], feed_dict={x: train_x, y: train_y})\n",
    "        tb_writer.add_summary(tb_scalar_cost_report, training_epoch)\n",
    "        \n",
    "        if training_epoch % 1000 == 0:\n",
    "            print('epoch: ', training_epoch, ' cost: ', cost_function_result)\n",
    "    \n",
    "    # feed predictor with test data and print results\n",
    "    res = sess.run(pred, feed_dict={x: test_x})\n",
    "    print(\"Weight(s): \")\n",
    "    print(sess.run(W))\n",
    "    print(\"Predidctions for: \")\n",
    "    print(test_x)\n",
    "    print(\"is: \")\n",
    "    print(res)\n",
    "    print('100Km/h = 62.13712mph')\n",
    "\n",
    "# tensorboard.exe --logdir=\".\\tensorboard_example\" --port 9000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
